{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# youtube ëª¨ë“ˆ ë§Œë“¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "from oauth2client.tools import argparser\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "import pandas_gbq\n",
    "import pandas as pd\n",
    "\n",
    "#youtube\n",
    "#######################################\n",
    "my_youtube_1 ='AIzaSyDH8Pq7ddkmMJhA0kni5kBEe1UPBy31H70'\n",
    "my_youtube_2 ='AIzaSyAPLm-070e6WYKq2YN2WIqIzbqqrQkU3N4'\n",
    "my_youtube_api=my_youtube_2\n",
    "\n",
    "DEVELOPER_KEY = my_youtube_api\n",
    "YOUTUBE_API_SERVICE_NAME = \"youtube\"\n",
    "YOUTUBE_API_VERSION = \"v3\"\n",
    "FREEBASE_SEARCH_URL = \"https://www.googleapis.com/freebase/v3/search?%s\"\n",
    "\n",
    "youtube=build(YOUTUBE_API_SERVICE_NAME,YOUTUBE_API_VERSION,developerKey=DEVELOPER_KEY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## videos tableì— ëˆ„ì í•˜ëŠ” í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def videos_df_input(input_list):\n",
    "    global videos_df\n",
    "    videos_df.loc[len(videos_df)] = input_list\n",
    "    \n",
    "def playlists_df_input(input_list):\n",
    "    global playlists_df\n",
    "    playlists_df.loc[len(playlists_df)] = input_list\n",
    "\n",
    "def clear_videos_df(videos_col_list):\n",
    "    global videos_df  # í•¨ìˆ˜ ë‚´ì—ì„œ ì „ì—­ ë³€ìˆ˜ videos_dfë¥¼ ìˆ˜ì •í•˜ê¸° ìœ„í•´ global í‚¤ì›Œë“œ ì‚¬ìš©\n",
    "    videos_df = pd.DataFrame(columns=videos_col_list)  # ë¹ˆ DataFrameìœ¼ë¡œ ì´ˆê¸°í™”\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def making_youtube_table(last_execute_date,channel_name,playlist_name_list,i):\n",
    "    #last_execute_date : ë§ˆì§€ë§‰ ëŒ€ê·¸ ì‹¤í–‰ ë‚ ì§œ\n",
    "    ###ì±„ë„ ì•„ì´ë”” í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ \n",
    "    #DataFrameì— í•œ í–‰ì”© ë“¤ì–´ê°ˆ ì¸ìŠ¤í„´ìŠ¤(ë¦¬ìŠ¤íŠ¸ í˜•ì‹)\n",
    "    videos_col_list=['video_id','playlist_id','video_url','thumb_img','video_title','video_views','date']\n",
    "            \n",
    "    input_list=[None for i in range(len(videos_col_list))] #videoí…Œì´ë¸”ì— ë„£ì„ ë¹ˆë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
    "    \n",
    "    #qëŠ” ì›í•˜ëŠ” ì±„ë„ ì´ë¦„\n",
    "    search_response=youtube.search().list(\n",
    "        q=channel_name,\n",
    "        type='channel', #ì±„ë„ë§Œ\n",
    "        part='snippet',\n",
    "        maxResults=1, #ì±„ë„ ì•„ì´ë””ë§Œ ë½‘ì•„ì˜¬ ê²ƒì´ë¯€ë¡œ í•˜ë‚˜ì˜ ê²°ê´ê°’ë§Œ ìš”êµ¬\n",
    "        ).execute()\n",
    "\n",
    "    #ê²€ìƒ‰í•œ ì±„ë„ê³ ìœ ì•„ì´ë””\n",
    "    channel_id = search_response['items'][0]['snippet']['channelId']\n",
    "\n",
    "    #ì¬ìƒëª©ë¡ê³¼ ìƒê´€ì—†ì´ ìµœì‹ ìˆœìœ¼ë¡œ ì¶”ì¶œí•œë‹¤.\n",
    "    channel_response = youtube.channels().list(\n",
    "        part='contentDetails', \n",
    "        id=channel_id\n",
    "        ).execute()\n",
    "\n",
    "    uploads_playlist_id = channel_response['items'][0]['contentDetails']['relatedPlaylists']['uploads'] #ìµœì‹ ìˆœìœ¼ë¡œ ë‹¨ìˆœ ì¶”ì¶œ\n",
    "    \n",
    "    input_list[1]=uploads_playlist_id\n",
    "    \n",
    "    playlistitems = youtube.playlistItems().list(\n",
    "        part='snippet', \n",
    "        playlistId=uploads_playlist_id, \n",
    "        maxResults=5 #ì—°ìŠµì´ë¯€ë¡œ íšŸìˆ˜ë¥¼ ì œí•œí•œë‹¤, í”„ë¡œì íŠ¸ ì§„í–‰ì‹œ maxê°’ì€ ì—†ë‹¤.\n",
    "        )\n",
    "\n",
    "    playlist_short_items=(playlistitems.execute())['items']\n",
    "    \n",
    "    #ê°ê°ì˜ ì˜ìƒë³„ description or titleì„ í†µí•´ ìƒí˜¸ëª… ì¶”ì¶œ\n",
    "    #ì—¬ê¸°ë¶€í„°ëŠ” ê° ì±„ë„ì˜ descriptionì´ ìƒì´í•˜ë¯€ë¡œ í•˜ë“œì½”ë”©ìœ¼ë¡œ ìƒí˜¸ëª…ì„ ì¶”ì¶œ\n",
    "    each_extract(playlist_short_items,channel_name,input_list,last_execute_date)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_info_input(input_list, video_id):\n",
    "    input_list[2]=f\"https://www.youtube.com/watch?v={video_id}\"\n",
    "    video_infos=youtube.videos().list(\n",
    "        part='snippet, statistics',\n",
    "        id=video_id,\n",
    "        #order='date'\n",
    "        ).execute()\n",
    "    input_list[3]=video_infos['items'][0]['snippet']['thumbnails']['medium']['url']\n",
    "    input_list[4]=video_infos['items'][0]['snippet']['title']\n",
    "    input_list[5]=int(video_infos['items'][0]['statistics']['viewCount'])\n",
    "    input_list[0]=video_id\n",
    "    input_list[6]=video_infos['items'][0]['snippet']['publishedAt'][:10]\n",
    "    return input_list\n",
    "\n",
    "def restaurant_list_input(matches,video_id):\n",
    "    global restaurant_in_video_list\n",
    "    global video_id_restaurant_list\n",
    "    \n",
    "    restaurant_in_video_list.append(matches)\n",
    "    video_id_restaurant_list.append(video_id)\n",
    "    \n",
    "    \n",
    "def each_extract(playlist_short_items,channel_name,input_list,last_execute_date):\n",
    "    last_execute_date = pd.to_datetime(last_execute_date) #string to datetime\n",
    "    \n",
    "    if(channel_name=='ì„±ì‹œê²½ SUNG SI KYUNG'):\n",
    "        for dic in playlist_short_items:\n",
    "            #ìµœì‹ ìˆœìœ¼ë¡œ ë½‘ë‹¤ê°€ ì´ì „ ì‹¤í–‰ì‹œê°„ë³´ë‹¤ ì´ì „ì˜ ë°ì´í„°ë©´ ì¶”ì¶œ ì¤‘ë‹¨\n",
    "            matches_date = pd.to_datetime(dic['snippet']['publishedAt'])\n",
    "            if(matches_date <= last_execute_date):\n",
    "                break\n",
    "            pattern = r'\\[(.*?)\\]'\n",
    "            matches = re.findall(pattern, dic['snippet']['description']) #ê´„í˜¸ì•ˆì— ìˆëŠ” ìƒí˜¸ëª… ì¶”ì¶œ\n",
    "            matches = ''.join(matches) #to string            \n",
    "            if(matches):\n",
    "                video_id = dic['snippet']['resourceId']['videoId']\n",
    "                restaurant_list_input(matches,video_id)\n",
    "                videos_df_input(video_info_input(input_list, video_id))\n",
    "                \n",
    "    elif(channel_name=='ì˜ì•¼ë¯¸'):\n",
    "        for dic in playlist_short_items:\n",
    "            matches_date = pd.to_datetime(dic['snippet']['publishedAt'])\n",
    "            if(matches_date <= last_execute_date):\n",
    "                break\n",
    "            pattern = r'#(w+)'\n",
    "            matches = re.findall(pattern, dic['snippet']['title']) #ê´„í˜¸ì•ˆì— ìˆëŠ” ìƒí˜¸ëª… ì¶”ì¶œ\n",
    "            matches = ''.join(matches) #to string\n",
    "            if(matches != 'shorts' and matches != ''):\n",
    "                video_id = dic['snippet']['resourceId']['videoId']\n",
    "                restaurant_list_input(matches,video_id)\n",
    "                videos_df_input(video_info_input(input_list, video_id))\n",
    "    \n",
    "    elif(channel_name=='ì§€ë‰¼ë­ê°€ì´ë“œ'):\n",
    "         for dic in playlist_short_items:\n",
    "            matches_date = pd.to_datetime(dic['snippet']['publishedAt'])\n",
    "            if(matches_date <= last_execute_date):\n",
    "                break\n",
    "            pattern = r'â€¢ (.+)'\n",
    "            matches = re.findall(pattern, dic['snippet']['description'])\n",
    "            matches = [match for match in matches]\n",
    "            for match in matches:\n",
    "                match = ''.join(match) #to string\n",
    "                if(match):\n",
    "                    video_id = dic['snippet']['resourceId']['videoId']\n",
    "                    restaurant_list_input(match,video_id)\n",
    "            videos_df_input(video_info_input(input_list, video_id))\n",
    "                        \n",
    "    elif(channel_name=='ë–¡ë³¶í€¸ Tteokbokqueen'):\n",
    "         for dic in playlist_short_items:\n",
    "            matches_date = pd.to_datetime(dic['snippet']['publishedAt'])\n",
    "            if(matches_date <= last_execute_date):\n",
    "                break\n",
    "            pattern = r'\\[(.*?)\\]'\n",
    "            matches = re.findall(pattern, dic['snippet']['description']) #ê´„í˜¸ì•ˆì— ìˆëŠ” ìƒí˜¸ëª… ì¶”ì¶œ\n",
    "            matches = [match for match in matches]\n",
    "            for match in matches:\n",
    "                video_id = dic['snippet']['resourceId']['videoId']\n",
    "                restaurant_list_input(match,video_id)\n",
    "            videos_df_input(video_info_input(input_list, video_id))\n",
    "    \n",
    "    elif(channel_name=='ì •ìœ¡ì™• MeatCreator'):\n",
    "         for dic in playlist_short_items:\n",
    "            matches_date = pd.to_datetime(dic['snippet']['publishedAt'])\n",
    "            if(matches_date <= last_execute_date):\n",
    "                break\n",
    "            pattern = r'\\\"(.*?)\\\"'\n",
    "            matches = re.findall(pattern, dic['snippet']['description']) #ê´„í˜¸ì•ˆì— ìˆëŠ” ìƒí˜¸ëª… ì¶”ì¶œ\n",
    "            matches = ''.join(matches) #to string            \n",
    "            if(matches):\n",
    "                video_id = dic['snippet']['resourceId']['videoId']\n",
    "                restaurant_list_input(matches,video_id)\n",
    "                videos_df_input(video_info_input(input_list, video_id))\n",
    "                \n",
    "    elif(channel_name=='ê¹€ì‚¬ì›ì„¸ë¼'):\n",
    "        for dic in playlist_short_items:\n",
    "            matches_date = pd.to_datetime(dic['snippet']['publishedAt'])\n",
    "            if(matches_date <= last_execute_date):\n",
    "                break\n",
    "            pattern = re.compile(r'\\[ì‹ë‹¹ì •ë³´\\]\\n(.+)')\n",
    "            matches = re.search(pattern, dic['snippet']['description'])\n",
    "            text=dic['snippet']['description']\n",
    "            if(matches):\n",
    "                video_id = dic['snippet']['resourceId']['videoId']\n",
    "                matched_text = matches.group(1)  # Get the part of the match after '\\n'\n",
    "                print(matched_text[0]>='0' and matched_text[0]<='9')\n",
    "                if(matched_text[0]>='0' and matched_text[0]<='9'):\n",
    "                    # [ì‹ë‹¹ì •ë³´] ë‹¤ìŒì˜ ë‚´ìš©ì„ ì¶”ì¶œ\n",
    "                    restaurant_start = text.find(\"[ì‹ë‹¹ì •ë³´]\")\n",
    "                    restaurant_end = text.find(\"- ì·¨ë¯¸ë¡œ ìœ íŠœë¸Œ í•˜ê³  ìˆìŠµë‹ˆë‹¤\", restaurant_start)\n",
    "\n",
    "                    if restaurant_start != -1 and restaurant_end != -1:\n",
    "                        restaurant_info = text[restaurant_start:restaurant_end]\n",
    "                        \n",
    "                        # ìˆ«ìì™€ 'ë²ˆ. ' ë’¤ì— ì˜¤ëŠ” ë¬¸ìì—´ì„ ì œì™¸í•˜ê³  í•œê¸€ ë¬¸ìì—´ë§Œ ì¶”ì¶œ\n",
    "                        restaurant_names = re.findall(r'\\d+\\.\\s+(.*?)\\n', restaurant_info)\n",
    "                        \n",
    "                        # 'ë²ˆ. ' ë¶€ë¶„ì„ ì œê±°í•˜ê³  ì¶œë ¥\n",
    "                        for name in restaurant_names:\n",
    "                            matched_text = re.sub(r'\\d+\\.\\s+', '', name)\n",
    "                            restaurant_list_input(matched_text,video_id)\n",
    "                else:\n",
    "                    restaurant_list_input(matched_text,video_id)\n",
    "                    \n",
    "                videos_df_input(video_info_input(input_list, video_id))\n",
    "        \n",
    "    elif(channel_name=='íšŒì‚¬ë‘RawFishEater'):\n",
    "        for dic in playlist_short_items:\n",
    "            matches_date = pd.to_datetime(dic['snippet']['publishedAt'])\n",
    "            if(matches_date <= last_execute_date):\n",
    "                break\n",
    "            pattern = r\"- ì‹ë‹¹ëª… : (.+)\"\n",
    "            matches = re.findall(pattern, dic['snippet']['description'])\n",
    "            matches = ''.join(matches) #to string \n",
    "            if(matches):\n",
    "                video_id = dic['snippet']['resourceId']['videoId']\n",
    "                restaurant_list_input(matches,video_id)\n",
    "                videos_df_input(video_info_input(input_list, video_id))\n",
    "    \n",
    "    elif(channel_name=='ê¹€ì§¬ë½•'):\n",
    "        for dic in playlist_short_items:\n",
    "            matches_date = pd.to_datetime(dic['snippet']['publishedAt'])\n",
    "            if(matches_date <= last_execute_date):\n",
    "                break\n",
    "            pattern = r\"ìƒí˜¸ : (.+)\"\n",
    "            matches = re.findall(pattern, dic['snippet']['description'])\n",
    "            matches = ''.join(matches) #to string \n",
    "            if(matches):\n",
    "                video_id = dic['snippet']['resourceId']['videoId']\n",
    "                restaurant_list_input(matches,video_id)\n",
    "                videos_df_input(video_info_input(input_list, video_id))\n",
    "    \n",
    "    elif(channel_name=='ì¡°ì´í•œë¼'):\n",
    "        for dic in playlist_short_items:\n",
    "            matches_date = pd.to_datetime(dic['snippet']['publishedAt'])\n",
    "            if(matches_date <= last_execute_date):\n",
    "                break\n",
    "            matches = re.findall(r'I\\s(.*?)\\sI', dic['snippet']['description'])\n",
    "            matches = ''.join(matches) #to string \n",
    "            if(matches):\n",
    "                video_id = dic['snippet']['resourceId']['videoId']\n",
    "                restaurant_list_input(matches,video_id)\n",
    "                videos_df_input(video_info_input(input_list, video_id))\n",
    "                \n",
    "    elif(channel_name=='ì¡ì‹ê³µë£¡'):\n",
    "        for dic in playlist_short_items:\n",
    "            matches_date = pd.to_datetime(dic['snippet']['publishedAt'])\n",
    "            if(matches_date <= last_execute_date):\n",
    "                break\n",
    "            pattern = r\"ğŸ“(.+)\"\n",
    "            matches = re.findall(pattern, dic['snippet']['description'])\n",
    "            matches = ''.join(matches).strip() #to string \n",
    "            if(matches):\n",
    "                video_id = dic['snippet']['resourceId']['videoId']\n",
    "                restaurant_list_input(matches,video_id)\n",
    "                videos_df_input(video_info_input(input_list, video_id))\n",
    "         \n",
    "    elif(channel_name=='ì„¬ë§ˆì„í›ˆíƒœTV'):\n",
    "        for dic in playlist_short_items:\n",
    "            matches_date = pd.to_datetime(dic['snippet']['publishedAt'])\n",
    "            if(matches_date <= last_execute_date):\n",
    "                break\n",
    "            matches = re.findall(r'ğŸ”ì •ë³´ğŸ”\\s*\\n\\s*ìƒí˜¸:(.*?)\\s*\\n', dic['snippet']['description'])\n",
    "            matches = ''.join(matches).strip() #to string \n",
    "            if(matches):\n",
    "                matches=matches.strip()\n",
    "                video_id = dic['snippet']['resourceId']['videoId']\n",
    "                restaurant_list_input(matches,video_id)\n",
    "                videos_df_input(video_info_input(input_list, video_id))\n",
    "    \n",
    "    elif(channel_name=='ë§›ìˆê² ë‹¤ Yummy'):\n",
    "        for dic in playlist_short_items:\n",
    "            matches_date = pd.to_datetime(dic['snippet']['publishedAt'])\n",
    "            if(matches_date <= last_execute_date):\n",
    "                break\n",
    "            matches = re.findall(r'#(\\S+)', dic['snippet']['description'])\n",
    "            matches=list(set(matches))\n",
    "            exclude_substring=['ë§›ìˆê² ë‹¤','yummy']\n",
    "            matches=[s for s in matches if all(excl not in s for excl in exclude_substring)]\n",
    "            for match in matches:\n",
    "                match=match.strip()\n",
    "                video_id = dic['snippet']['resourceId']['videoId']\n",
    "                restaurant_list_input(match,video_id)\n",
    "            videos_df_input(video_info_input(input_list, video_id))\n",
    "    \n",
    "    elif(channel_name =='ë¨¹ê°±_Mukgang'):\n",
    "        for dic in playlist_short_items:\n",
    "            matches_date = pd.to_datetime(dic['snippet']['publishedAt'])\n",
    "            if(matches_date <= last_execute_date):\n",
    "                break\n",
    "            matches = re.search(r'ì˜¤ëŠ˜ì˜ ì‹ë‹¹ : \\[([^\\]]+)\\]', dic['snippet']['description'])\n",
    "            if(matches):\n",
    "                matches = matches.group(1)\n",
    "                video_id = dic['snippet']['resourceId']['videoId']\n",
    "                restaurant_list_input(matches,video_id)\n",
    "                videos_df_input(video_info_input(input_list, video_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### videosë¥¼ ë¹…ì¿¼ë¦¬ì— ì €ì¥í•˜ëŠ” í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_videos_to_bigquery(videos_df):\n",
    "    rename_videos_column=['video_id','playlist_id','video_url','thumb_img','video_title','video_views','date']\n",
    "    videos_df.columns=rename_videos_column\n",
    "\n",
    "    videos_df['date'] = pd.to_datetime(videos_df['date'])\n",
    "    videos_df['video_views'].astype(int)\n",
    "\n",
    "    # ì„œë¹„ìŠ¤ ê³„ì • ì¸ì¦ ì •ë³´ê°€ ë‹´ê¸´ JSON íŒŒì¼ ê²½ë¡œ\n",
    "    KEY_PATH = \"./mz_map_servoce_account.json\"\n",
    "    # Credentials ê°ì²´ ìƒì„±\n",
    "    credentials = service_account.Credentials.from_service_account_file(\n",
    "        KEY_PATH, scopes=[\"https://www.googleapis.com/auth/cloud-platform\"],\n",
    "    )\n",
    "    # ë¹…ì¿¼ë¦¬ í´ë¼ì´ì–¸íŠ¸ ê°ì²´ ìƒì„±\n",
    "    client = bigquery.Client(credentials = credentials, project = credentials.project_id)\n",
    "\n",
    "    project_name = 'summer-pattern-398307'\n",
    "    dataset_name = 'MZ_map_table'\n",
    "    videos_table_name = 'videos'\n",
    "    videos_destination_table = dataset_name + '.' + videos_table_name\n",
    "    # í…Œì´ë¸” ID\n",
    "    #table_id = \"[í”„ë¡œì íŠ¸ ì´ë¦„].[ë°ì´í„° ì„¸íŠ¸ ì´ë¦„].[í…Œì´ë¸” ì´ë¦„]\"\n",
    "\n",
    "    #videos_df ì‚½ì…\n",
    "    #if_exists='replace' or 'append'\n",
    "    videos_df.to_gbq(videos_destination_table,project_name,if_exists='append',credentials=credentials)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### restauarnts df ìƒì„±"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### bigqueryì— ì €ì¥í•˜ëŠ” í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_restaurants_to_bigquery(restaurants_df):\n",
    "    # ì„œë¹„ìŠ¤ ê³„ì • ì¸ì¦ ì •ë³´ê°€ ë‹´ê¸´ JSON íŒŒì¼ ê²½ë¡œ\n",
    "    KEY_PATH = \"./mz_map_servoce_account.json\"\n",
    "    # Credentials ê°ì²´ ìƒì„±\n",
    "    credentials = service_account.Credentials.from_service_account_file(\n",
    "        KEY_PATH, scopes=[\"https://www.googleapis.com/auth/cloud-platform\"],\n",
    "    )\n",
    "    # ë¹…ì¿¼ë¦¬ í´ë¼ì´ì–¸íŠ¸ ê°ì²´ ìƒì„±\n",
    "    client = bigquery.Client(credentials = credentials, project = credentials.project_id)\n",
    "\n",
    "    project_name = 'summer-pattern-398307'\n",
    "    dataset_name = 'MZ_map_table'\n",
    "    restaurants_table_name = 'restaurants'\n",
    "    restaurants_destination_table = dataset_name + '.' +restaurants_table_name\n",
    "    # í…Œì´ë¸” ID\n",
    "    #table_id = \"[í”„ë¡œì íŠ¸ ì´ë¦„].[ë°ì´í„° ì„¸íŠ¸ ì´ë¦„].[í…Œì´ë¸” ì´ë¦„]\"\n",
    "\n",
    "    #videos_df ì‚½ì…\n",
    "    #if_exists='replace' or 'append'\n",
    "    restaurants_df.to_gbq(restaurants_destination_table,project_name,if_exists='append',credentials=credentials)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### restaurants df ìƒì„± í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def making_restaurants_table(restaurant_in_video_list,video_id_restaurant_list):\n",
    "    my_map_restapi_key = 'ef692e63b23382e5f866e76b99b38b40'\n",
    "    \n",
    "    #restaurantsí…Œì´ë¸” ìƒì„±\n",
    "    restaurants_col_list=['restaurant_name',\n",
    "                        'video_id',\n",
    "                        'address',\n",
    "                        'location_x',\n",
    "                        'location_y',\n",
    "                        'place_url']\n",
    "    restaurants_list=[]\n",
    "    restaurants_df=pd.DataFrame(restaurants_list,columns=restaurants_col_list)\n",
    "\n",
    "\n",
    "    def place_to_info(place,my_RESP_API_key,video_id):\n",
    "        \n",
    "        url = 'https://dapi.kakao.com/v2/local/search/keyword.json'\n",
    "        params = {'query': place,'page': 1}\n",
    "        headers = {\"Authorization\": \"KakaoAK \"+my_RESP_API_key}\n",
    "        try:\n",
    "            places = requests.get(url, params=params, headers=headers).json()['documents'][0]\n",
    "            \n",
    "            input_list=[place,\n",
    "                        video_id,\n",
    "                        places['address_name'],\n",
    "                        float(places['x']),\n",
    "                        float(places['y']),\n",
    "                        places['place_url']]\n",
    "        except:\n",
    "            global cnt\n",
    "            print(cnt)\n",
    "            cnt+=1\n",
    "            input_list=[place,video_id,None,None,None,None]\n",
    "        \n",
    "        global restaurants_df\n",
    "        restaurants_df.loc[len(restaurants_df)]=input_list\n",
    "\n",
    "    def clear_restaurants_df(restaurants_col_list):\n",
    "        global restaurants_df  # í•¨ìˆ˜ ë‚´ì—ì„œ ì „ì—­ ë³€ìˆ˜ videos_dfë¥¼ ìˆ˜ì •í•˜ê¸° ìœ„í•´ global í‚¤ì›Œë“œ ì‚¬ìš©\n",
    "        restaurants_df = pd.DataFrame(columns=restaurants_col_list)  # ë¹ˆ DataFrameìœ¼ë¡œ ì´ˆê¸°í™”\n",
    "        \n",
    "    clear_restaurants_df(restaurants_col_list)\n",
    "    place_list=list(set(restaurant_in_video_list))\n",
    "    for i,place in enumerate(place_list):\n",
    "        place_to_info(place,my_map_restapi_key,video_id_restaurant_list[i])\n",
    "    \n",
    "    #bigqueryì— ì €ì¥\n",
    "    input_restaurants_to_bigquery(restaurants_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### restaurant_category df ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def making_restaurants_table(restaurant_in_video_list):\n",
    "    restaurant_in_video_list=list(set(restaurant_in_video_list))\n",
    "\n",
    "    my_map_restapi_key = 'ef692e63b23382e5f866e76b99b38b40'\n",
    "\n",
    "    def making_restaurant_category_df(restaurant_in_video_list, my_REST_API_key):\n",
    "        category_list = []\n",
    "        for place in restaurant_in_video_list:\n",
    "            url = 'https://dapi.kakao.com/v2/local/search/keyword.json'\n",
    "            params = {'query': place,'page': 1}\n",
    "            headers = {\"Authorization\": \"KakaoAK \"+my_REST_API_key}\n",
    "            # try:\n",
    "            #     places = requests.get(url, params=params, headers=headers).json()['documents'][0]\n",
    "            #     category_list.append(places['category_name'])\n",
    "            # except:\n",
    "            #     category_list.append(None)\n",
    "            try:\n",
    "                places = requests.get(url, params=params, headers=headers).json()['documents'][0]\n",
    "                category_list.append(places['category_name'])\n",
    "                #print(places['category_name'])\n",
    "            except:\n",
    "                category_list.append(None)\n",
    "\n",
    "        restaurant_category_df=pd.DataFrame(list(zip(restaurant_in_video_list, category_list)),columns=['restaurant_name','category'])\n",
    "        \n",
    "        return restaurant_category_df\n",
    "\n",
    "    \n",
    "    restaurant_category_df=making_restaurant_category_df(restaurant_in_video_list, my_map_restapi_key)\n",
    "    \n",
    "    input_restaurant_category_to_bigquery(restaurant_category_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_restaurant_category_to_bigquery(restaurant_category_df):\n",
    "    # ì„œë¹„ìŠ¤ ê³„ì • ì¸ì¦ ì •ë³´ê°€ ë‹´ê¸´ JSON íŒŒì¼ ê²½ë¡œ\n",
    "    KEY_PATH = \"./mz_map_servoce_account.json\"\n",
    "    # Credentials ê°ì²´ ìƒì„±\n",
    "    credentials = service_account.Credentials.from_service_account_file(\n",
    "        KEY_PATH, scopes=[\"https://www.googleapis.com/auth/cloud-platform\"],\n",
    "    )\n",
    "    # ë¹…ì¿¼ë¦¬ í´ë¼ì´ì–¸íŠ¸ ê°ì²´ ìƒì„±\n",
    "    client = bigquery.Client(credentials = credentials, project = credentials.project_id)\n",
    "\n",
    "    project_name = 'summer-pattern-398307'\n",
    "    dataset_name = 'MZ_map_table'\n",
    "    restaurant_category_table_name = 'restaurant_category'\n",
    "    restaurant_category_destination_table = dataset_name + '.' +restaurant_category_table_name\n",
    "    # í…Œì´ë¸” ID\n",
    "    #table_id = \"[í”„ë¡œì íŠ¸ ì´ë¦„].[ë°ì´í„° ì„¸íŠ¸ ì´ë¦„].[í…Œì´ë¸” ì´ë¦„]\"\n",
    "\n",
    "    #videos_df ì‚½ì…\n",
    "    #if_exists='replace' or 'append'\n",
    "    restaurant_category_df.to_gbq(restaurant_category_destination_table,project_name,if_exists='append',credentials=credentials)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# videosì™€ restaurants, restaurant_categoryë¥¼ ëª¨ë‘ í•˜ëŠ” ë©”ì¸ í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(last_execute_date):\n",
    "    #videoì •ë³´ì—ì„œ ì¶”ì¶œí•œ ë ˆìŠ¤í† ë‘ ì •ë³´ë¥¼ ë°›ëŠ” ë¦¬ìŠ¤íŠ¸\n",
    "    restaurant_in_video_list=[]\n",
    "    #ë ˆìŠ¤í† ë‘ì˜ ë¹„ë””ì˜¤ ì¶œì²˜ ë¦¬ìŠ¤íŠ¸\n",
    "    video_id_restaurant_list=[]\n",
    "\n",
    "    # ì±„ë„,í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸\n",
    "    # 5ê°œ í•­ëª©ì”© ì •ë ¬\n",
    "    channel_name_list=['ì„±ì‹œê²½ SUNG SI KYUNG','ì˜ì•¼ë¯¸','ë–¡ë³¶í€¸ Tteokbokqueen','ì§€ë‰¼ë­ê°€ì´ë“œ','ì •ìœ¡ì™• MeatCreator',\n",
    "                    'ê¹€ì‚¬ì›ì„¸ë¼','íšŒì‚¬ë‘RawFishEater','ê¹€ì§¬ë½•','ì¡°ì´í•œë¼','ì¡ì‹ê³µë£¡',\n",
    "                    'ì„¬ë§ˆì„í›ˆíƒœTV','ë§›ìˆê² ë‹¤ Yummy','ë¨¹ë³´ìŠ¤ ì­ˆì—½ì´','ë¨¹ê°±_Mukgang'\n",
    "                    ]\n",
    "    playlist_name_list=[['ì„±ì‹œê²½ì˜ ë¨¹ì„í…ë°'],[''],['ë–¡ë³¶í€¸ ì‹ë‹¹','ë–¡ë³¶ì´ íˆ¬ì–´ ì„œìš¸ (In Seoul)'],['ì„œìš¸ 3ëŒ€ ë§›ì§‘','ì¸ìƒ ì° ë§›ì§‘','ë–¡ë³¶ì´ ë§›ì§‘'],['KR ë¼ì§€ê³ ê¸° ë§›ì§‘','ì–‘ê³ ê¸° ë§›ì§‘','ì •ìœ¡ì™• ë ˆìŠ¤í† ë‘ ë§›ì§‘','ëˆê¹ŒìŠ¤ ë§›ì§‘','ì¸ìƒ ë§›ì§‘'],\n",
    "                        ['[ì„œìš¸ë§›ì§‘] ì™¸ì‹ì¸ìƒ 10ë…„ì°¨ì˜ ì„œìš¸ ìˆ¨ì€ ë§›ì§‘ ì†Œê°œ'],['ì„œìš¸ í¸ ëª°ì•„ë³´ê¸°'],[''],[''],[''],\n",
    "                        ['ì„¬ë§ˆì„í›ˆíƒœ ì„œìš¸'],['ì„œìš¸(Seoul)'],['ë¨¹ì–´ì£¼ì—½'],['ğŸ’œë§›ìˆëŠ” ì•¼ì™¸ë¨¹ë°©ğŸ’œ']\n",
    "                        ]\n",
    "\n",
    "    #ROOT(ì „ì²´ ì½”ë“œ)\n",
    "\n",
    "    #videos ì´ˆê¸°í™”\n",
    "    videos_column=['video_id','playlist_id','video_url','thumb_img','video_title','video_views','date']\n",
    "    videos_df=pd.DataFrame(columns=videos_column)\n",
    "\n",
    "    #videos df ìƒì„±\n",
    "    for i,name in enumerate(channel_name_list[0:14]):\n",
    "        making_youtube_table(last_execute_date,name,playlist_name_list,i)\n",
    "    \n",
    "    input_videos_to_bigquery(videos_df)\n",
    "    \n",
    "    #ê°™ì´ ìƒì„±ëœ resaurant_in_video_listë¥¼ ê°€ì§€ê³  restaurants ìƒì„±\n",
    "    making_restaurants_table(restaurant_in_video_list,video_id_restaurant_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
